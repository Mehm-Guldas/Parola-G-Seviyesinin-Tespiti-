PROJE KAYIT DOSYASI (ADIM ADIM) - Parola Güç Seviyesi Sınıflandırma

Proje Adı:
Yapay Sinir Ağları ve Doğal Dil İşleme Teknikleri ile Parola Güç Seviyesinin Tespiti ve Sınıflandırılması

Amaç:
Verilen bir parolanın güç seviyesini (0=Zayıf, 1=Orta, 2=Güçlü) sınıflandıran bir model geliştirmek.
Hocanın temel beklentisi: projede YAPAY SİNİR AĞI kullanarak bir sınıflandırma modeli eğitmek.

Veri Seti:
- Kaynak: Password Strength Classifier Dataset (Kaggle)
  https://www.kaggle.com/datasets/bhavikbb/password-strength-classifier-dataset/data
- Yerel dosya: archive/data.csv
- Şema:
  - password: parola metni (string)
  - strength: etiket (int) {0,1,2}
- Veri büyüklüğü: ~669,881 satır

Not:
Bu kayıt dosyası, projede yaptıklarımızı adım adım özetlemek içindir. Rapor yazarken bu dosyayı referans al.

=====================
ADIM 1 — Ortam ve Kütüphaneler
=====================
Hedef ortam:
- Python 3.x
- (Tercih) Google Colab ile eğitim

Kullanılacak kütüphaneler:
- pandas, numpy
- scikit-learn (TF-IDF, split, metrikler)
- tensorflow / keras (MLP yapay sinir ağı)
- matplotlib, seaborn (grafikler)

=====================
ADIM 2 — Veriyi Yükleme
=====================
1) data.csv dosyasını pandas ile oku.
2) İlk kontrol:
   - Kolon isimleri: password, strength
   - Eksik değer var mı? (NaN/boş string)
   - strength alanı sadece {0,1,2} mi?

Beklenen çıktı:
- df.head()
- df.info()
- df['strength'].value_counts()

=====================
ADIM 3 — Temizleme ve Ön İşleme
=====================
1) password alanını string’e çevir.
2) Boş parola / NaN varsa temizle.
3) (Opsiyonel) Çok uç/garip örnekleri incele (çok uzun/çok kısa).

Önemli karar:
- Parolalarda büyük-küçük harf bilgisi önemli olabileceği için genelde lowercase yapmak zorunlu değil.

=====================
ADIM 4 — Veri Bölme (Train/Val/Test)
=====================
1) Stratified split uygulanacak:
   - Train: %80
   - Test: %20
2) Train içinde ayrıca validation ayrılabilir:
   - Train: %70
   - Val: %10
   - Test: %20

Beklenen çıktı:
- Her split için sınıf dağılımları (value_counts).

=====================
ADIM 5 — Özellik Çıkarma (NLP kısmı)
=====================
Ana yaklaşım (dokümanla uyumlu): Karakter tabanlı TF-IDF
- TfidfVectorizer(analyzer='char', ngram_range=(2,5)) gibi bir ayar.
- Amaç: parolanın karakter örüntülerini yakalamak.

(Opsiyonel) Manuel özellikler (feature engineering):
- length
- digit_count
- upper_count
- lower_count
- special_count
- unique_char_count

Not:
Bu manuel özellikler TF-IDF ile birleştirilebilir (scikit-learn FeatureUnion ya da scipy.sparse hstack).

=====================
ADIM 6 — Baseline Model (Yapay Sinir Ağı: MLP)
=====================
Model hedefi:
- Girdi: TF-IDF (ve varsa ek özellikler)
- Çıkış: 3 sınıf (softmax)

MLP önerisi (Keras):
- Dense(256, relu) + Dropout
- Dense(128, relu) + Dropout
- Dense(3, softmax)

Eğitim:
- loss: sparse_categorical_crossentropy
- optimizer: adam
- metrics: accuracy
- early stopping: val_loss ile

Beklenen çıktı:
- Eğitim/validasyon accuracy-loss grafikleri
- Test seti sonuçları

=====================
ADIM 7 — Değerlendirme (Rapor için zorunlu gibi düşün)
=====================
Metrikler:
- Accuracy
- Macro F1-score (sınıflar dengesiz ise daha anlamlı)
- Classification report
- Confusion matrix (ısı haritası)

Ek analiz:
- Yanlış sınıflanan örneklerden 15-30 adet örnek göster ve yorumla.

=====================
ADIM 8 — “Küçük Geliştirme / Ek Yorum” (Ödevi güçlendirmek için)
=====================
Amaç: Aynı problemi farklı bir yöntemle çalıştırıp karşılaştırma yapmak.

Önerilen ek model (çok düşük efor, güçlü baseline):
- TF-IDF (char ngram) + LinearSVC (veya LogisticRegression)

Karşılaştırma:
- MLP vs LinearSVC
- Aynı train/test split ile
- Tablo halinde accuracy ve macro-F1 yaz

Beklenen katkı cümlesi:
- “YSA tabanlı MLP yaklaşımına ek olarak doğrusal bir sınıflandırıcı ile karşılaştırma yapılmıştır. Karakter n-gram temsilleri ile LinearSVC hızlı ve güçlü bir alternatif olarak değerlendirilmiştir.”

=====================
ADIM 9 — Çıktıların Kaydı ve Tekrarlanabilirlik
=====================
1) Kullanılan parametreler:
- TF-IDF ngram_range
- MLP katman boyutları, dropout, epoch, batch size
- Split random_state

2) Kaydedilecekler:
- confusion matrix görseli
- eğitim grafikleri
- final metrik tablosu

=====================
ADIM 10 — Makale/Bildiri Formatı (Raporu buna göre yaz)
=====================
Bölüm önerisi:
1) Giriş
2) İlgili Çalışmalar (kısa)
3) Veri Seti
4) Yöntem
   - TF-IDF (char n-gram)
   - MLP mimarisi
   - Ek model (LinearSVC) (varsa)
5) Deneysel Kurulum
6) Sonuçlar
7) Tartışma (hata analizi)
8) Sonuç ve Gelecek Çalışmalar
9) Kaynakça

Kaynakça/Atıf notu:
- Kaggle veri setini mutlaka atıfla.
- proje.txt içindeki Melicher et al. (2016) ve Rehman et al. (2024) kaynaklarını “Related Work” kısmında 2-3 cümleyle bağla.

=====================
SONRAKİ ADIM (Uygulamaya başlama)
=====================
Bir sonraki adımda Python eğitim kodunu yazacağız:
- Veri okuma + split
- TF-IDF pipeline
- MLP eğitimi
- değerlendirme + görseller
- (opsiyonel) LinearSVC karşılaştırması

Kayıt Notu (Tarih/Sürüm):
- 2025-12-22: Proje planı ve uygulanacak adımlar kayıt altına alındı.

=====================
ADIM 11 — Colab Üzerinde Çalıştırma (Kod ve Talimat)
=====================
Bu adımda eğitim kodu hazırlandı ve Colab'de çalıştırılacak.

Kod dosyası:
- train_colab_password_strength.py

Colab çalışma adımları:
1) Google Colab'de yeni bir notebook aç.
2) Sol menüden "Files" bölümüne gir.
3) Bu projedeki dosyaları Colab'e yükle:
   - train_colab_password_strength.py
   - archive/data.csv  (archive klasörüyle birlikte yüklemek daha kolay)
4) Colab'de bir hücrede şu komutu çalıştır:
   !python train_colab_password_strength.py

Çalışınca beklenenler:
- Split boyutları (train/val/test) ve sınıf dağılımı ekrana yazılır.
- Keras MLP modeli eğitilir (EarlyStopping ile).
- Eğitim grafikleri (loss ve accuracy) çizilir.
- Test için classification report + confusion matrix çizilir.
- Yanlış sınıflanan örneklerden rastgele bir liste ekrana basılır.

Opsiyonel karşılaştırma:
- Kod içinde sklearn baseline açık (run_sklearn_baseline=True).
- Bu kısım TF-IDF(char 2-5) + LinearSVC ile karşılaştırma metriği üretir.

Notlar (rapor için):
- MLP kısmı "yapay sinir ağı kullanıldı" şartını karşılar.
- LinearSVC kısmı "alternatif yöntemle karşılaştırma" katkısı sağlar.
- Aynı split ile karşılaştırma yapıldığını raporda belirt.

Kayıt Notu (Tarih/Sürüm):
- 2025-12-22: Colab eğitim kodu eklendi (train_colab_password_strength.py) ve çalıştırma talimatı kayıt altına alındı.

=====================
YAPILANLAR (LOG) — GERÇEKLEŞEN ADIMLAR
=====================
- 2025-12-22: train_colab_password_strength.py oluşturuldu (TF-IDF + MLP(YSA) + değerlendirme + opsiyonel LinearSVC).
- 2025-12-22: data.csv okuma hatası düzeltildi. Bazı parolalarda virgül (,) bulunduğu için pandas ParserError oluşuyordu; load_data() fonksiyonu, hata durumunda satırı en sağdan 1 virgülle bölerek (rpartition) güvenli parse edecek şekilde güncellendi.

=====================
ADIM 12 — Diğer Modellerle Eğitim (LogReg, RandomForest)
=====================
Amaç:
- Mevcut MLP ve LinearSVC sonuçlarına ek olarak farklı model ailelerini (LogisticRegression ve RandomForest) denemek ve karşılaştırma tablosu oluşturmak.

Kod dosyası:
- train_other_models.py

Colab çalışma adımları:
1) train_other_models.py dosyasını ve archive/data.csv dosyasını Colab çalışma dizinine (/content) yükle.
2) Colab'de şu komutu çalıştır:
   !python train_other_models.py

Beklenen çıktılar:
- [TF-IDF (char 2-5) + LogisticRegression] için Accuracy ve Macro-F1 ile classification_report çıktısı.
- [RandomForest (manual features)] için Accuracy ve Macro-F1 ile classification_report çıktısı.
- Her iki model için confusion matrix.

Yapılanlar (Log):
- 2025-12-25: train_other_models.py oluşturuldu. Bu dosyada:
  - Karakter tabanlı TF-IDF ile LogisticRegression modeli eğitilmesi,
  - Sadece manuel özellikler (uzunluk, rakam/büyük/küçük/özel karakter sayıları) ile RandomForest eğitilmesi,
  - Her iki modelin Accuracy ve Macro-F1 metrikleri ile detaylı classification_report çıktılarının alınması planlandı.
  - 2025-12-25: train_other_models.py'de pd.read_csv() 'errors' parametresi kaldırıldı; hata durumunda manuel parse'a geçecek şekilde düzeltme yapıldı.
